---
marp: true
math: mathjax
theme: uncover
backgroundColor: #1e1e1e
color: white
---

# Salud Mental en el Entorno Laboral
 
*"Mens sana in corpore sano"*

---

## Introducci√≥n

En el mundo laboral, las altas exigencias pueden provocar estr√©s, ansiedad o malestar psicol√≥gico.  
A pesar de su importancia, **existe a√∫n un estigma importante** en torno a los problemas de salud mental, lo que dificulta su detecci√≥n temprana y el acceso a recursos de apoyo.

---

## Objetivo del trabajo

Desarrollar un **modelo predictivo** capaz de anticipar si una persona podr√≠a necesitar tratamiento psicol√≥gico, a partir de sus respuestas en una **encuesta an√≥nima** y estandarizada.

El modelo deber√°:
- Identificar patrones relevantes.
- Detectar factores de riesgo.
- Ser interpretable y √∫til en contextos reales.

---

## Enfoque y valor

Queremos mostrar c√≥mo el aprendizaje autom√°tico puede **aportar valor en √°mbitos humanos sensibles**, siempre con responsabilidad y criterio √©tico.

---

## An√°lisis exploratorio de datos (EDA)

- Exploramos la distribuci√≥n del target y las variables m√°s relevantes.

- Identificaremos patrones y relaciones √∫tiles para el modelado posterior.

---

## Target: `treatment`
![Distribuci√≥n del target](./src/img/distribucion_target.png)

---

## `age` vs `treatment`

![Distribuci√≥n de edad seg√∫n tratamiento](./src/img/age_vs_treatment.png)

---

## `family_history` vs `treatment`

![Comparativa de historial familiar](./src/img/family_history_vs_treatment.png)

---

## `interfere` vs `treatment`

![Frecuencia de interferencia con el trabajo](./src/img/work_interfere_vs_treatment.png)

---

## Feature engineering

En esta fase seleccionamos las variables que se utilizar√°n como predictores (`X`) y la variable objetivo (`y`), y preparamos los datos para entrenar modelos de clasificaci√≥n.

---

## Construcci√≥n de `X`, `y`

- Separamos las variables por tipo:
  - Ordinales
  - Num√©ricas
  - Categ√≥ricas: variables tipo encuesta

- Creamos los set con lo que trabajaremos:

```python
X = df_modificable[ordinales + numericas + categoricas].copy()
y = df_modificable["treatment"]
```

---

## Dos versiones de `X`: sin escalar y escalada

Aplicamos One-Hot Encoding a las categ√≥ricas:

```python
ohe = OneHotEncoder(drop="first", sparse_output=False)
```
- X_raw: con OneHot, sin escalar age ‚Üí √∫til para modelos de √°rboles

- X_scaled: con OneHot + escalado de age ‚Üí √∫til para regresi√≥n o KNN

---

## Dos versiones de `X`: sin escalar y escalada

Escalamos `age` con `StandardScaler` en una de las versiones:

```python
pre_scaling = ColumnTransformer([
    ("num", StandardScaler(), numericas),
    ("cat", ohe, categoricas)
], remainder="passthrough")
```

---

## Train-test split

Dividimos los datos en conjunto de entrenamiento y conjunto de test para poder **evaluar el rendimiento real** de los modelos sobre datos no vistos.

```python
from sklearn.model_selection import train_test_split

X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(
    X_raw, y, test_size=0.2, stratify=y, random_state=42)

X_train_scaled, X_test_scaled, y_train_scaled, y_test_scaled = train_test_split(
    X_scaled, y, test_size=0.2, stratify=y, random_state=42)
```

---

## Baseline: Regresi√≥n log√≠stica

Usamos un modelo de **regresi√≥n log√≠stica simple** como baseline.  

Como la regresi√≥n log√≠stica es sensible a la escala, usamos `X_scaled`:

```python
baseline = LogisticRegression(max_iter=1000, random_state=42)
baseline.fit(X_train_scaled, y_train_scaled)

y_pred_base = baseline.predict(X_test_scaled)
```

---

## M√©tricas de evaluaci√≥n

- **Accuracy**: porcentaje total de aciertos.
- **Precision**: de los casos predichos como positivos, cu√°ntos lo eran realmente.
- **Recall**: de los casos positivos reales, cu√°ntos fueron correctamente identificados.
- **F1 Score**: media arm√≥nica entre *precision* y *recall*.

---

## M√©tricas de evaluaci√≥n

En nuestro contexto, **el recall es especialmente importante**,  
ya que nos interesa **detectar correctamente a quienes necesitan tratamiento**.  
Aun as√≠, usaremos el **F1 Score** como referencia global por equilibrar ambas.

---

## M√©tricas del baseline

| M√©trica     | Valor     |
|-------------|-----------|
| Accuracy    | **0.8287** |
| Precision   | **0.8281** |
| Recall      | **0.8346** |
| F1 Score    | **0.8314** |

Estos valores nos servir√°n como punto de partida para comparar con modelos m√°s avanzados.

---

## Matriz de confusi√≥n: baseline

![Frecuencia de interferencia con el trabajo](./src/img/mat_conf_logreg.png)

---

## Random Forest

Random Forest es un ensamblado de √°rboles de decisi√≥n que ofrece una buena capacidad de generalizaci√≥n y robustez frente al overfitting.

Utilizaremos en su modelado `X_raw`, sin escalar, y aplicaremos un `GridSearchCV` para encontrar la mejor combinaci√≥n de hiperpar√°metros.

---

```python
# Instanciamos el modelo
rf = RandomForestClassifier(random_state=42)

# Hiperpar√°metros optimizados
param_grid = {
    "n_estimators": [100],
    "max_depth": [None],
    "min_samples_split": [5],
    "min_samples_leaf": [1],
    "max_features": ["log2"],
    "bootstrap": [True]
}

# GridSearch con validaci√≥n cruzada
grid_rf = GridSearchCV(
    estimator=rf,
    param_grid=param_grid,
    cv=5,
    scoring="f1_macro",
    n_jobs=-1,
    verbose=1
)

grid_rf.fit(X_train_raw, y_train_raw)
y_pred_rf = grid_rf.best_estimator_.predict(X_test_raw)
```

---

## M√©tricas: Random Forest

| M√©trica    | Valor   |
|------------|---------|
| Accuracy   | **0.8367** |
| Precision  | **0.8028** |
| Recall     | **0.8976** |
| F1 Score   | **0.8476** |

En este modelo mejoramos el recall considerablemente, manteniendo un buen equilibrio general.  

---

## Matriz de confusi√≥n: RF

![Frecuencia de interferencia con el trabajo](./src/img/mat_conf_rf.png)

---

## XGBoost

XGBoost es un modelo de boosting basado en √°rboles de decisi√≥n que ofrece gran rendimiento y control sobre el ajuste, construyendo predictores de forma secuencial para corregir errores del modelo anterior.

Utilizaremos en su modelo `X_raw`, sin escalar, y aplicaremos un `GridSearchCV` para encontrar la mejor combinaci√≥n de hiperpar√°metros.

---

```python
# Instanciamos el modelo
xgb = XGBClassifier(objective="binary:logistic", eval_metric="logloss", random_state=42)

# Hiperpar√°metros optimizados
param_grid = {
    "n_estimators": [250],
    "max_depth": [3],
    "learning_rate": [0.02],
    "subsample": [1.0],
    "colsample_bytree": [1.0],
    "gamma": [0.05]
}

# GridSearch con validaci√≥n cruzada
grid_xgb = GridSearchCV(
    estimator=xgb,
    param_grid=param_grid,
    cv=5,
    scoring="f1_macro",
    verbose=1,
    n_jobs=-1
)

grid_xgb.fit(X_train_raw, y_train_raw)
y_pred_xgb = grid_xgb.best_estimator_.predict(X_test_raw)
```

---

## M√©tricas: XGBoost

| M√©trica     | Valor     |
|-------------|-----------|
| Accuracy    | **0.8367** |
| Precision   | **0.7945** |
| Recall      | **0.9134** |
| F1 Score    | **0.8498** |

En este modelo se logra el **mejor recall** hasta el momento, lo cual es muy relevante para nuestro caso de uso.

---

## Matriz de confusi√≥n: XGBoost

![Matriz XGBoost](./src/img/mat_conf_xgb.png)

---

## Gradient Boosting

Gradient Boosting es un algoritmo que construye √°rboles de decisi√≥n de forma secuencial, donde cada nuevo √°rbol intenta corregir los errores cometidos por los anteriores.

Utilizaremos en su modelado `X_raw`, sin escalar, y aplicaremos un `GridSearchCV` para encontrar la mejor combinaci√≥n de hiperpar√°metros.

---

```python
# Instanciamos el modelo base
gbc = GradientBoostingClassifier(random_state=42)

# Hiperpar√°metros optimizados
param_grid = {
    "n_estimators": [275],
    "max_depth": [4],
    "learning_rate": [0.0075],
    "subsample": [0.9],
    "max_features": ["log2"]
}

# GridSearch con validaci√≥n cruzada
grid_gbc = GridSearchCV(
    estimator=gbc,
    param_grid=param_grid,
    cv=5,
    scoring="f1_macro",
    n_jobs=-1,
    verbose=1
)

grid_gbc.fit(X_train_raw, y_train_raw)
y_pred_gbc = grid_gbc.best_estimator_.predict(X_test_raw)
```

---

## M√©tricas: Gradient Boosting

| M√©trica    | Valor     |
|------------|-----------|
| Accuracy   | **0.8486** |
| Precision  | **0.8156** |
| Recall     | **0.9055** |
| F1 Score   | **0.8582** |

En este modelo mejoramos en pr√°cticamente todos los par√°metros, obteniendo el mejor equilibrio general hasta ahora.

---

## Matriz de confusi√≥n: GBC

![Frecuencia de interferencia con el trabajo](./src/img/mat_conf_gbc.png)

---

## K-Nearest Neighbors (KNN)

K-Nearest Neighbors es un algoritmo basado en la similitud entre instancias. Clasifica seg√∫n los $k$ vecinos m√°s cercanos.

Es un modelo no param√©trico y muy intuitivo, √∫til como referencia frente a modelos m√°s complejos. Requiere que los datos est√©n escalados, por lo que usamos `X_scaled`.

---

```python
# Instanciamos el modelo base
knn = KNeighborsClassifier()

# Hiperpar√°metros optimizados
param_grid = {
    "n_neighbors": [27],
    "weights": ["uniform"],
    "metric": ["minkowski"],
    "p": [4]
}

# GridSearch con validaci√≥n cruzada
grid_knn = GridSearchCV(
    estimator=knn,
    param_grid=param_grid,
    scoring="f1_macro",
    cv=5,
    verbose=1,
    n_jobs=-1
)

grid_knn.fit(X_train_scaled, y_train_scaled)
y_pred_knn = grid_knn.best_estimator_.predict(X_test_scaled)
```

---

### M√©tricas: KNN

| M√©trica    | Valor     |
|------------|-----------|
| Accuracy   | **0.8247** |
| Precision  | **0.7986** |
| Recall     | **0.8740** |
| F1 Score   | **0.8346** |

KNN ofrece un *recall* decente y una ejecuci√≥n sencilla, aunque, en general, con peor rendimiento que los dem√°s modelos.

---

### Matriz de confusi√≥n: KNN

![Matriz de confusi√≥n del modelo KNN](./src/img/mat_conf_knn.png)

---

## Comparativa de modelos

| Modelo           | Accuracy | Precisi√≥n | Recall  | F1 Score |
|------------------|----------|-----------|---------|----------|
| Baseline         | 0.8287   | 0.8281    | 0.8346  | 0.8314   |
| RF               | 0.8367   | 0.8028    | 0.8976  | 0.8476   |
| XGBoost          | 0.8367   | 0.7945    | 0.9134  | 0.8498   |
| GBC              | 0.8486   | 0.8156    | 0.9055  | 0.8582   |
| KNN              | 0.8247   | 0.7986    | 0.8740  | 0.8346   |

---

## Conclusiones

**Gradient Boosting** es el modelo seleccionado:
- El mejor **F1 Score**
- La mejor **accuracy**
- El segundo mejor en **precisi√≥n** y **recall**

---

## Mejora y an√°lisis del modelo

Comprobar si es posible mantener (o incluso mejorar) el rendimiento reduciendo la complejidad del modelo o comprendiendo mejor su comportamiento.

---

## An√°lisis de importancia de variables

- Detectar qu√© variables son m√°s influyentes en la predicci√≥n.
- Evaluar la posibilidad de eliminar variables con muy poca relevancia.
- Explorar versiones simplificadas del modelo utilizando solo las variables m√°s importantes.

---

## Variables m√°s relevantes

![Gr√°fico de importancia](./src/img/feature_importance_gbc.png)

---

### Reentrenamiento con $n$ variables

```python
# Lista para ir guardando los resultados
results = []

# Bucle para ir probando los modelos con n features
for n in range(1, len(feat_imp) + 1, 2):
    top_features = feat_imp["feature"].head(n).tolist()

    # Conjuntos X adaptados a las features elegidas
    X_train_top = X_train_raw[top_features]
    X_test_top = X_test_raw[top_features]

    # Entrenamos con los hiperpar√°metros √≥ptimos
    model = GradientBoostingClassifier(
        learning_rate=0.0075,
        max_depth=4,
        max_features="log2",
        n_estimators=275,
        subsample=0.9,
        random_state=42
    )
    model.fit(X_train_top, y_train_raw)
    y_pred = model.predict(X_test_top)

    # Guardamos las m√©tricas
    results.append({
        "n_features": n,
        "accuracy": accuracy_score(y_test_raw, y_pred),
        "precision": precision_score(y_test_raw, y_pred),
        "recall": recall_score(y_test_raw, y_pred),
        "f1": f1_score(y_test_raw, y_pred)
    })

# Guardamos en DataFrame
results_df = pd.DataFrame(results)
```

---

![Gr√°fico de importancia](./src/img/optimal_n_features.png)

---

## ¬øCu√°ntas variables utilizar?

Se detectan **2 picos de rendimiento**:

- Modelo con **31 variables**: mejor **precisi√≥n**
- Modelo con **19 variables**: mejor **recall**.

Ambos tienen **accuracy** y **F1 Score** muy similares.

---

## ¬øPor qu√© priorizamos el recall?

Nuestro caso trata sobre **salud mental**.

Lo importante es **no dejar pasar** personas que necesiten ayuda.

Preferimos **maximizar el recall**:
- Aunque aumenten los falsos positivos,
- Garantizamos que **nadie que necesite intervenci√≥n se quede fuera**.

---

## Conclusi√≥n: $n=19$

üîπ Mejor **recall**, clave en este problema.

üîπ Menor complejidad ‚Üí modelo m√°s **simple e interpretable**.

üîπ Rendimiento muy similar al modelo m√°s grande.

---

## Modelo final

Tras aplicar t√©cnicas de optimizaci√≥n, selecci√≥n de variables por importancia y validaci√≥n cruzada, hemos construido un modelo final basado en **Gradient Boosting**.

Este modelo ha sido entrenado utilizando las **19 variables m√°s relevantes** y los **hiperpar√°metros √≥ptimos**, logrando un gran rendimiento con buena interpretabilidad.

---

## Guardado del modelo

Utilizamos `joblib` para guardar en local el modelo obtenido:

```python
# Guardamos el modelo final entrenado
joblib.dump(model_19, "./src/models/optimal_model_mental_health.pkl")
```

---

## Conclusiones (I)

- El mejor modelo es **Gradient Boosting con 19 variables**.
- Presenta el mejor equilibrio entre rendimiento y simplicidad.
- Alta puntuaci√≥n en F1 Score, precisi√≥n y recall.
- Modelo interpretable y robusto, con buen potencial de generalizaci√≥n.

---

## Conclusiones (II)

- Variables m√°s influyentes:
  - `work_interfere`: impacto de la salud mental en el trabajo.
  - `family_history_Yes`: antecedentes familiares.
  - `benefits_Yes`: acceso a recursos en el entorno laboral.

- Tambi√©n destacan variables sociodemogr√°ficas: pa√≠s, edad y g√©nero.

---

## Conclusiones (III)

- Permite anticipar casos que podr√≠an requerir intervenci√≥n psicol√≥gica.
- √ötil para orientar recursos preventivos en contextos laborales.
- Aporta transparencia gracias al an√°lisis de interpretabilidad.
- Ejemplo claro de c√≥mo aplicar machine learning con impacto social.

---

Este proyecto va mucho m√°s all√° de m√©tricas y predicciones.

Hablamos de personas.

Detectar a tiempo qui√©n necesita ayuda puede marcar la diferencia entre el silencio y la intervenci√≥n, entre la invisibilidad y el cuidado.

Si los datos pueden ayudarnos a entender mejor la salud mental, tenemos la responsabilidad de usarlos con humanidad, criterio y compromiso.

**Gracias.**


